"""docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªã«é–¢ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰.

ã“ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®å“è³ªã¨æ•´åˆæ€§ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
"""

from pathlib import Path
import re

import pytest


class TestDocsQuality:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹."""

    @pytest.fixture
    def project_root(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾—."""
        return Path(__file__).parent.parent

    @pytest.fixture
    def docs_dir(self, project_root):
        """docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾—."""
        return project_root / "docs"

    def get_all_markdown_files(self, docs_dir):
        """docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—."""
        return list(docs_dir.rglob("*.md"))

    def test_markdown_files_have_titles(self, docs_dir):
        """ã™ã¹ã¦ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆH1ãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª."""
        markdown_files = self.get_all_markdown_files(docs_dir)

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # H1ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆ# ã§å§‹ã¾ã‚‹è¡Œï¼‰ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            h1_pattern = r"^# .+"
            assert re.search(
                h1_pattern, content, re.MULTILINE
            ), f"File '{md_file.relative_to(docs_dir)}' should have an H1 title"

    def test_internal_links_consistency(self, docs_dir):
        """å†…éƒ¨ãƒªãƒ³ã‚¯ã®æ•´åˆæ€§ã‚’ç¢ºèªï¼ˆè­¦å‘Šã®ã¿ï¼‰."""
        markdown_files = self.get_all_markdown_files(docs_dir)
        broken_links = []

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # ç›¸å¯¾ãƒ‘ã‚¹ã®ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
            relative_links = re.findall(
                r"\[.*?\]\(([^)]+\.md(?:#[^)]*)?)\)", content
            )

            for link in relative_links:
                # ã‚¢ãƒ³ã‚«ãƒ¼éƒ¨åˆ†ã‚’é™¤å»ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ã¿ã‚’å–å¾—
                file_path = link.split("#")[0] if "#" in link else link

                # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                if file_path.startswith("./"):
                    target_path = md_file.parent / file_path[2:]
                elif file_path.startswith("../"):
                    target_path = md_file.parent / file_path
                else:
                    target_path = md_file.parent / file_path

                # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è­¦å‘Šãƒªã‚¹ãƒˆã«è¿½åŠ 
                if not target_path.exists():
                    broken_links.append(
                        f"'{file_path}' from '{md_file.relative_to(docs_dir)}'"
                    )

        # å£Šã‚ŒãŸãƒªãƒ³ã‚¯ã¯è­¦å‘Šã¨ã—ã¦è¡¨ç¤ºï¼ˆãƒ†ã‚¹ãƒˆå¤±æ•—ã«ã¯ã—ãªã„ï¼‰
        if broken_links:
            print(f"Warning: Broken internal links found: {broken_links}")

    def test_no_broken_internal_links(self, docs_dir):
        """å£Šã‚ŒãŸå†…éƒ¨ãƒªãƒ³ã‚¯ãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆè­¦å‘Šã®ã¿ï¼‰."""
        markdown_files = self.get_all_markdown_files(docs_dir)
        broken_links = []

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # å†…éƒ¨ãƒªãƒ³ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            link_pattern = r"\[([^\]]+)\]\(([^)]+\.md)\)"
            links = re.findall(link_pattern, content)

            for link_text, file_path in links:
                # å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
                if file_path.startswith("http"):
                    continue

                # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                if file_path.startswith("/"):
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®çµ¶å¯¾ãƒ‘ã‚¹
                    target_path = docs_dir.parent / file_path.lstrip("/")
                else:
                    # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
                    target_path = md_file.parent / file_path

                if not target_path.exists():
                    broken_links.append(
                        f"'{file_path}' in '{md_file.relative_to(docs_dir)}' (text: '{link_text}')"
                    )

        # å£Šã‚ŒãŸãƒªãƒ³ã‚¯ã¯è­¦å‘Šã¨ã—ã¦è¡¨ç¤ºï¼ˆãƒ†ã‚¹ãƒˆå¤±æ•—ã«ã¯ã—ãªã„ï¼‰
        if broken_links:
            print(f"Warning: Broken internal links found: {broken_links}")

    def test_consistent_heading_style(self, docs_dir):
        """è¦‹å‡ºã—ã‚¹ã‚¿ã‚¤ãƒ«ã®ä¸€è²«æ€§ã‚’ç¢ºèªï¼ˆSetextã‚¹ã‚¿ã‚¤ãƒ«ã®ç¦æ­¢ï¼‰ï¼ˆè­¦å‘Šã®ã¿ï¼‰."""
        markdown_files = self.get_all_markdown_files(docs_dir)
        setext_headings = []

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                lines = f.readlines()

            # Setextã‚¹ã‚¿ã‚¤ãƒ«ã®è¦‹å‡ºã—ï¼ˆ= ã¾ãŸã¯ - ã®ä¸‹ç·šï¼‰ã‚’æ¤œå‡º
            for i, line in enumerate(lines[1:], 1):  # 2è¡Œç›®ã‹ã‚‰é–‹å§‹
                if re.match(r"^=+\s*$", line.strip()) or re.match(
                    r"^-+\s*$", line.strip()
                ):
                    setext_headings.append(
                        f"'{md_file.relative_to(docs_dir)}' at line {i + 1}"
                    )

        # Setextã‚¹ã‚¿ã‚¤ãƒ«ã®è¦‹å‡ºã—ã¯è­¦å‘Šã¨ã—ã¦è¡¨ç¤ºï¼ˆãƒ†ã‚¹ãƒˆå¤±æ•—ã«ã¯ã—ãªã„ï¼‰
        if setext_headings:
            print(
                f"Warning: Setext-style headings found (use ATX-style # ## ### instead): {setext_headings}"
            )

    def test_no_trailing_whitespace(self, docs_dir):
        """è¡Œæœ«ã®ç©ºç™½ãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆè­¦å‘Šã®ã¿ï¼‰."""
        markdown_files = self.get_all_markdown_files(docs_dir)
        trailing_whitespace_files = []

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                lines = f.readlines()

            for i, line in enumerate(lines, 1):
                # è¡Œæœ«ã«ç©ºç™½ãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆæ”¹è¡Œæ–‡å­—ã¯é™¤ãï¼‰
                if line.rstrip("\n\r").endswith(" ") or line.rstrip(
                    "\n\r"
                ).endswith("\t"):
                    trailing_whitespace_files.append(
                        f"'{md_file.relative_to(docs_dir)}' at line {i}"
                    )
                    break  # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«1ã¤ã®è­¦å‘Šã§ååˆ†

        # è¡Œæœ«ç©ºç™½ã¯è­¦å‘Šã¨ã—ã¦è¡¨ç¤ºï¼ˆãƒ†ã‚¹ãƒˆå¤±æ•—ã«ã¯ã—ãªã„ï¼‰
        if trailing_whitespace_files:
            print(
                f"Warning: Trailing whitespace found in: {trailing_whitespace_files}"
            )

    def test_proper_code_block_language(self, docs_dir):
        """ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã«é©åˆ‡ãªè¨€èªæŒ‡å®šãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª."""
        markdown_files = self.get_all_markdown_files(docs_dir)

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # ãƒ•ã‚§ãƒ³ã‚¹ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```ï¼‰ã‚’æ¤œç´¢
            code_blocks = re.findall(r"```(\w*)\n", content)

            for _i, lang in enumerate(code_blocks):
                # è¨€èªæŒ‡å®šãŒãªã„ç©ºã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’è­¦å‘Š
                if not lang:
                    # ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯è¨€èªæŒ‡å®šãªã—ã‚’è¨±å¯ã™ã‚‹å ´åˆã‚‚ã‚ã‚‹
                    # ã“ã“ã§ã¯å³å¯†ã«ãƒã‚§ãƒƒã‚¯ã—ãªã„ãŒã€æ¨å¥¨ã¨ã—ã¦è¨˜éŒ²
                    pass

    def test_consistent_emoji_usage(self, docs_dir):
        """çµµæ–‡å­—ã®ä¸€è²«ã—ãŸä½¿ç”¨ã‚’ç¢ºèª."""
        markdown_files = self.get_all_markdown_files(docs_dir)

        # è¨±å¯ã•ã‚ŒãŸçµµæ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
        allowed_emoji_patterns = [
            r"ğŸ“‹",  # æ¦‚è¦
            r"ğŸ“",  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ§‹æˆ
            r"ğŸ¤–",  # AIé–‹ç™ºè€…å‘ã‘
            r"ğŸ",  # åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            r"ğŸ› ï¸",  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰é–‹ç™º
            r"ğŸ¨",  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é–‹ç™º
            r"ğŸš€",  # ãƒªãƒªãƒ¼ã‚¹ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤
            r"ğŸ”´",  # å„ªå…ˆåº¦: é«˜
            r"ğŸŸ¡",  # å„ªå…ˆåº¦: ä¸­
            r"ğŸŸ¢",  # å„ªå…ˆåº¦: ä½
            r"ğŸ”",  # ã‚ˆãã‚ã‚‹å‚ç…§ãƒ‘ã‚¿ãƒ¼ãƒ³
            r"ğŸ“Œ",  # é–‹ç™ºã®é€²ã‚æ–¹
            r"ğŸ—ï¸",  # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
            r"ğŸ”Œ",  # APIä»•æ§˜
            r"ğŸ“–",  # é‹ç”¨ãƒ»åˆ©ç”¨ã‚¬ã‚¤ãƒ‰
            r"ğŸ”§",  # é–‹ç™ºé–¢é€£
        ]

        for md_file in markdown_files:
            with open(md_file, "r", encoding="utf-8") as f:
                content = f.read()

            # çµµæ–‡å­—ã‚’æ¤œç´¢ï¼ˆåŸºæœ¬çš„ãªUnicodeçµµæ–‡å­—ç¯„å›²ï¼‰
            emoji_pattern = r"[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002600-\U000027BF\U0001F900-\U0001F9FF]"
            found_emojis = re.findall(emoji_pattern, content)

            # è¦‹ã¤ã‹ã£ãŸçµµæ–‡å­—ãŒè¨±å¯ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            for emoji in found_emojis:
                is_allowed = any(
                    re.search(pattern, emoji)
                    for pattern in allowed_emoji_patterns
                )
                if not is_allowed:
                    # è­¦å‘Šã¨ã—ã¦è¨˜éŒ²ï¼ˆå¿…ãšã—ã‚‚ã‚¨ãƒ©ãƒ¼ã«ã—ãªã„ï¼‰
                    pass


class TestDocsLinkIntegrity:
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–“ã®ãƒªãƒ³ã‚¯æ•´åˆæ€§ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹."""

    @pytest.fixture
    def project_root(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾—."""
        return Path(__file__).parent.parent

    @pytest.fixture
    def docs_dir(self, project_root):
        """docsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾—."""
        return project_root / "docs"

    def test_readme_links_to_existing_files(self, docs_dir):
        """README.mdã‹ã‚‰ã®ãƒªãƒ³ã‚¯ãŒå­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª."""
        readme_path = docs_dir / "README.md"

        with open(readme_path, "r", encoding="utf-8") as f:
            content = f.read()

        # Markdownãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
        md_links = re.findall(r"\[.*?\]\(([^)]+\.md(?:#[^)]*)?)\)", content)

        for link in md_links:
            file_path = link.split("#")[0] if "#" in link else link
            target_path = docs_dir / file_path
            assert (
                target_path.exists()
            ), f"README.md links to non-existent file: {file_path}"

    def test_bidirectional_link_consistency(self, docs_dir):
        """åŒæ–¹å‘ãƒªãƒ³ã‚¯ã®æ•´åˆæ€§ã‚’ç¢ºèªï¼ˆè­¦å‘Šã®ã¿ï¼‰."""
        readme_path = docs_dir / "README.md"
        if not readme_path.exists():
            pytest.skip("README.md not found")

        with open(readme_path, "r", encoding="utf-8") as f:
            readme_content = f.read()

        # README.mdã‹ã‚‰ãƒªãƒ³ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        link_pattern = r"\[([^\]]+)\]\(([^)]+\.md)\)"
        readme_links = re.findall(link_pattern, readme_content)

        missing_back_links = []
        for _link_text, file_path in readme_links:
            target_path = docs_dir / file_path
            if target_path.exists():
                with open(target_path, "r", encoding="utf-8") as f:
                    target_content = f.read()

                # å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰README.mdã¸ã®é€†ãƒªãƒ³ã‚¯ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                back_link_patterns = [
                    r"\[.*?\]\(\.\./README\.md\)",
                    r"\[.*?\]\(README\.md\)",
                    r"\[.*?\]\(\./README\.md\)",
                ]

                has_back_link = any(
                    re.search(pattern, target_content)
                    for pattern in back_link_patterns
                )
                if not has_back_link:
                    missing_back_links.append(file_path)

        # é€†ãƒªãƒ³ã‚¯ã®æ¬ å¦‚ã¯è­¦å‘Šã¨ã—ã¦è¡¨ç¤ºï¼ˆãƒ†ã‚¹ãƒˆå¤±æ•—ã«ã¯ã—ãªã„ï¼‰
        if missing_back_links:
            print(
                f"Warning: Files without back-links to README.md: {missing_back_links}"
            )


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆã‚’ç›´æ¥å®Ÿè¡Œã™ã‚‹å ´åˆ
    pytest.main([__file__, "-v"])
